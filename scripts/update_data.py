"""
è‡ªè¨‚è³‡æ–™æ›´æ–°è…³æœ¬ - å¯ä»¥æŒ‡å®šè¦æ–°å¢çš„æ–‡ä»¶
"""
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.document_loader import DocumentLoader
from src.vector_store import VectorStore
from config import Config


def add_specific_files(file_paths):
    """æ–°å¢ç‰¹å®šæ–‡ä»¶åˆ°å‘é‡è³‡æ–™åº«"""
    print("=" * 60)
    print("è‡ªè¨‚è³‡æ–™æ›´æ–°")
    print("=" * 60)
    
    # åˆå§‹åŒ–
    loader = DocumentLoader(Config.DATA_PATH)
    vector_store = VectorStore()
    
    # é¡¯ç¤ºç•¶å‰ç‹€æ…‹
    info = vector_store.get_collection_info()
    print(f"\nç•¶å‰æ–‡ä»¶æ•¸: {info['count']}")
    
    # è¼‰å…¥æŒ‡å®šæ–‡ä»¶
    all_docs = []
    for file_path in file_paths:
        if not os.path.exists(file_path):
            print(f"âš ï¸  æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")
            continue
            
        print(f"\nğŸ“‚ è¼‰å…¥: {file_path}")
        docs = loader.load_file(file_path)
        all_docs.extend(docs)
        print(f"âœ“ è¼‰å…¥ {len(docs)} å€‹ç‰‡æ®µ")
    
    if not all_docs:
        print("\nâŒ æ²’æœ‰è¼‰å…¥ä»»ä½•æ–‡ä»¶")
        return
    
    # åˆ†å‰²æ–‡ä»¶
    print(f"\nâœ‚ï¸  åˆ†å‰²æ–‡ä»¶æˆå€å¡Š...")
    chunked_docs = loader.chunk_documents(all_docs, chunk_size=500, overlap=50)
    print(f"å…± {len(chunked_docs)} å€‹æ–‡ä»¶å€å¡Š")
    
    # æ–°å¢åˆ°è³‡æ–™åº«
    print(f"\nğŸš€ æ–°å¢åˆ°å‘é‡è³‡æ–™åº«...")
    vector_store.add_documents(chunked_docs)
    
    # é¡¯ç¤ºçµæœ
    final_info = vector_store.get_collection_info()
    print(f"\n{'=' * 60}")
    print(f"âœ… æ›´æ–°å®Œæˆï¼")
    print(f"{'=' * 60}")
    print(f"æ–‡ä»¶ç¸½æ•¸: {info['count']} â†’ {final_info['count']}")
    print(f"æ–°å¢: {final_info['count'] - info['count']} å€‹æ–‡ä»¶å€å¡Š")


def remove_old_data_and_reload():
    """æ¸…é™¤èˆŠè³‡æ–™ä¸¦é‡æ–°è¼‰å…¥æ‰€æœ‰æ–‡ä»¶"""
    print("=" * 60)
    print("å®Œå…¨é‡å»ºè³‡æ–™åº«")
    print("=" * 60)
    
    # åˆªé™¤èˆŠè³‡æ–™
    vector_store = VectorStore()
    info = vector_store.get_collection_info()
    print(f"\nç›®å‰æœ‰ {info['count']} å€‹æ–‡ä»¶")
    
    confirm = input("\nâš ï¸  ç¢ºå®šè¦æ¸…é™¤æ‰€æœ‰è³‡æ–™ä¸¦é‡æ–°è¼‰å…¥ï¼Ÿ(yes/no): ")
    if confirm.lower() != 'yes':
        print("âŒ å·²å–æ¶ˆ")
        return
    
    vector_store.delete_collection()
    print("âœ“ å·²æ¸…é™¤èˆŠè³‡æ–™")
    
    # é‡æ–°è¼‰å…¥
    print("\nğŸ“‚ é‡æ–°è¼‰å…¥æ‰€æœ‰æ–‡ä»¶...")
    os.system("python scripts/load_data.py")


if __name__ == "__main__":
    print("\né¸æ“‡æ“ä½œæ¨¡å¼ï¼š")
    print("1. æ–°å¢ç‰¹å®šæ–‡ä»¶")
    print("2. å®Œå…¨é‡å»ºè³‡æ–™åº«")
    print("3. å–æ¶ˆ")
    
    choice = input("\nè«‹é¸æ“‡ (1/2/3): ")
    
    if choice == "1":
        print("\nè«‹è¼¸å…¥è¦æ–°å¢çš„æ–‡ä»¶è·¯å¾‘ï¼ˆç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰")
        print("ç¯„ä¾‹: data/agriculture/æ–°æ–‡ä»¶.txt")
        print("å¤šå€‹æ–‡ä»¶ç”¨é€—è™Ÿåˆ†éš”")
        
        paths = input("\næ–‡ä»¶è·¯å¾‘: ").strip()
        if paths:
            file_list = [p.strip() for p in paths.split(",")]
            add_specific_files(file_list)
        else:
            print("âŒ æœªè¼¸å…¥æ–‡ä»¶è·¯å¾‘")
    
    elif choice == "2":
        remove_old_data_and_reload()
    
    else:
        print("âŒ å·²å–æ¶ˆ")
